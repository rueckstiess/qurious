{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://localhost:5000\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Grid World dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style> .dataframe th, .dataframe tbody td { text-align: left; padding-right: 30px; } </style> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>env</th>\n",
       "      <th>size</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grid World:\\n. # . . .\\n. # . . .\\n. . . A G\\n. . . # .\\n. . # # .\\n\\nActions:\\n</td>\n",
       "      <td>right</td>\n",
       "      <td><pre>. # . . .<br>. # . . .<br>. . . A G<br>. . . # .<br>. . # # .<br></pre></td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Grid World:\\n. # . . .\\n. # . . .\\n. . . A G\\n. . . # .\\n. . # # .\\n\\nActions:\\nright</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grid World:\\n. . . . # . # . . .\\n# . . . . . . . . .\\n. . . . . # . . . .\\n. . . . . . . . . .\\n. G # . # . . . . .\\n. . . . . # . . # #\\n. . . . . . # . . .\\n. . . . . . # . # .\\n. . . . . . . . # .\\n. . . . . # . . # A\\n\\nActions:\\n</td>\n",
       "      <td>up up up left left up left up up left left left left left down</td>\n",
       "      <td><pre>. . . . # . # . . .<br># . . . . . . . . .<br>. . . . . # . . . .<br>. . . . . . . . . .<br>. G # . # . . . . .<br>. . . . . # . . # #<br>. . . . . . # . . .<br>. . . . . . # . # .<br>. . . . . . . . # .<br>. . . . . # . . # A<br></pre></td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>Grid World:\\n. . . . # . # . . .\\n# . . . . . . . . .\\n. . . . . # . . . .\\n. . . . . . . . . .\\n. G # . # . . . . .\\n. . . . . # . . # #\\n. . . . . . # . . .\\n. . . . . . # . # .\\n. . . . . . . . # .\\n. . . . . # . . # A\\n\\nActions:\\nup up up left left up left up up left left left left left down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grid World:\\n. # . A . . . .\\n. . . . . # . .\\n. G . # . . . .\\n# . . . . . . .\\n. . . # . . . .\\n. . . . . . # .\\n. . . . . # # .\\n. . . # . . . .\\n\\nActions:\\n</td>\n",
       "      <td>left down down left</td>\n",
       "      <td><pre>. # . A . . . .<br>. . . . . # . .<br>. G . # . . . .<br># . . . . . . .<br>. . . # . . . .<br>. . . . . . # .<br>. . . . . # # .<br>. . . # . . . .<br></pre></td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>Grid World:\\n. # . A . . . .\\n. . . . . # . .\\n. G . # . . . .\\n# . . . . . . .\\n. . . # . . . .\\n. . . . . . # .\\n. . . . . # # .\\n. . . # . . . .\\n\\nActions:\\nleft down down left</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from qurious.utils import display_pd_table\n",
    "\n",
    "with open(\"./grid_world_1k.jsonl\") as f:\n",
    "    data = [json.loads(line) for line in f.readlines()]\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"prompt\", \"response\", \"env\", \"size\", \"n_steps\"])\n",
    "df[\"text\"] = df[\"prompt\"] + df[\"response\"]\n",
    "df[\"env\"] = df[\"env\"].apply(lambda x: f\"<pre>{x}</pre>\")\n",
    "\n",
    "display_pd_table(df.head(3), replace_newlines=[\"env\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset contains 800 examples\n",
      "Test dataset contains 200 examples\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "\n",
    "print(f\"Training dataset contains {len(dataset['train'])} examples\")\n",
    "print(f\"Test dataset contains {len(dataset['test'])} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models and tokenizer with LoraManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: mps\n",
      "Loading base model: gpt2\n",
      "Creating adapter: default\n",
      "trainable params: 1179648 || all params: 125619456 || trainable%: 0.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomas/code/qurious/.venv/lib/python3.11/site-packages/peft/tuners/lora/layer.py:1264: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from qurious.config import Config\n",
    "from qurious.llms.lora_manager import LoraManager\n",
    "\n",
    "config = Config()\n",
    "config.model.base_model = \"gpt2\"\n",
    "config.training.batch_size = 4\n",
    "config.training.learning_rate = 5e-5\n",
    "config.training.scheduler_step_per_batch = True\n",
    "config.training.log_interval = 10\n",
    "\n",
    "lora_manager = LoraManager(config)\n",
    "\n",
    "# Get the PEFT model\n",
    "peft_model = lora_manager.get_model(\"default\")\n",
    "tokenizer = lora_manager.tokenizer\n",
    "\n",
    "# Make sure the model is in training mode and parameters require gradients\n",
    "peft_model.train()\n",
    "\n",
    "# Verify parameters require gradients\n",
    "trainable_params = 0\n",
    "all_param = 0\n",
    "for param in peft_model.parameters():\n",
    "    all_param += param.numel()\n",
    "    if param.requires_grad:\n",
    "        trainable_params += param.numel()\n",
    "\n",
    "print(\n",
    "    f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding the Training Dataset\n",
    "\n",
    "As a final step of dataset preparation, we need to apply padding to the training dataset. Padding ensures that all input sequences in a batch are of the same length.\n",
    "\n",
    "A crucial point to note is the need to add padding to the left. This approach is adopted because the model generates tokens autoregressively, meaning it continues from the last token. Adding padding to the right would cause the model to generate new tokens from these padding tokens, resulting in the output sequence including padding tokens in the middle.\n",
    "\n",
    "Padding to right\n",
    "```\n",
    "Today |  is  |   a    |  cold  |  <pad>  ==generate=>  \"Today is a cold <pad> day\"\n",
    " How  |  to  | become |  <pad> |  <pad>  ==generate=>  \"How to become a <pad> <pad> great engineer\".\n",
    "```\n",
    "\n",
    "Padding to left:\n",
    "```\n",
    "<pad> |  Today  |  is  |  a   |  cold     ==generate=>  \"<pad> Today is a cold day\"\n",
    "<pad> |  <pad>  |  How |  to  |  become   ==generate=>  \"<pad> <pad> How to become a great engineer\".\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c820d937af409a955fedad388a2edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b94eaa5cb4d48bf9b713dd1ff69a7a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style> .dataframe th, .dataframe tbody td { text-align: left; padding-right: 30px; } </style> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, ...]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "      <td>[50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, ...]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# You can use a different max length if your custom dataset has shorter/longer input sequences.\n",
    "MAX_LENGTH = 256\n",
    "\n",
    "\n",
    "def tokenize_and_pad_to_fixed_length(sample):\n",
    "    result = tokenizer(\n",
    "        sample[\"prompt\"],\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "\n",
    "tokenized_train_dataset = dataset[\"train\"].map(\n",
    "    tokenize_and_pad_to_fixed_length, remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "tokenized_eval_dataset = dataset[\"test\"].map(\n",
    "    tokenize_and_pad_to_fixed_length, remove_columns=dataset[\"test\"].column_names\n",
    ")\n",
    "\n",
    "assert all(len(x[\"input_ids\"]) == MAX_LENGTH for x in tokenized_train_dataset)\n",
    "\n",
    "display_pd_table(tokenized_train_dataset.select(range(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: mps\n",
      "MLFlow experiment 'maze-gpt2-finetune' started with run name 'loud-eel-800'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 17:23:04,342 - qurious.llms.trainer - INFO - Starting training for 5 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40b09f56eebb4da79ddfa12225cca07b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "2025-03-10 17:23:07,182 - qurious.llms.trainer - INFO - step 10: train_loss: 6.8347, epoch: 0, lr: 4.94e-05\n",
      "2025-03-10 17:23:09,650 - qurious.llms.trainer - INFO - step 20: train_loss: 5.2262, epoch: 0, lr: 4.89e-05\n",
      "2025-03-10 17:23:12,159 - qurious.llms.trainer - INFO - step 30: train_loss: 2.6965, epoch: 0, lr: 4.83e-05\n",
      "2025-03-10 17:23:14,684 - qurious.llms.trainer - INFO - step 40: train_loss: 1.6503, epoch: 0, lr: 4.78e-05\n",
      "2025-03-10 17:23:17,151 - qurious.llms.trainer - INFO - step 50: train_loss: 1.2354, epoch: 0, lr: 4.72e-05\n",
      "2025-03-10 17:23:19,622 - qurious.llms.trainer - INFO - step 60: train_loss: 1.2232, epoch: 0, lr: 4.66e-05\n",
      "2025-03-10 17:23:22,099 - qurious.llms.trainer - INFO - step 70: train_loss: 1.0506, epoch: 0, lr: 4.61e-05\n",
      "2025-03-10 17:23:24,568 - qurious.llms.trainer - INFO - step 80: train_loss: 1.1227, epoch: 0, lr: 4.55e-05\n",
      "2025-03-10 17:23:27,035 - qurious.llms.trainer - INFO - step 90: train_loss: 1.0011, epoch: 0, lr: 4.49e-05\n",
      "2025-03-10 17:23:29,504 - qurious.llms.trainer - INFO - step 100: train_loss: 1.0653, epoch: 0, lr: 4.44e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca7092bb3b0647c4b88446a4fa298832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 17:23:31,944 - qurious.llms.trainer - INFO - step 100: eval_loss: 0.8202\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d669954c029a4e53b406f1fcae720c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 17:23:34,446 - qurious.llms.trainer - INFO - step 110: train_loss: 1.1119, epoch: 1, lr: 4.38e-05\n",
      "2025-03-10 17:23:36,941 - qurious.llms.trainer - INFO - step 120: train_loss: 1.0363, epoch: 1, lr: 4.33e-05\n",
      "2025-03-10 17:23:39,438 - qurious.llms.trainer - INFO - step 130: train_loss: 0.9403, epoch: 1, lr: 4.27e-05\n",
      "2025-03-10 17:23:41,939 - qurious.llms.trainer - INFO - step 140: train_loss: 1.1389, epoch: 1, lr: 4.21e-05\n",
      "2025-03-10 17:23:44,504 - qurious.llms.trainer - INFO - step 150: train_loss: 0.8551, epoch: 1, lr: 4.16e-05\n",
      "2025-03-10 17:23:47,043 - qurious.llms.trainer - INFO - step 160: train_loss: 0.9845, epoch: 1, lr: 4.10e-05\n",
      "2025-03-10 17:23:49,539 - qurious.llms.trainer - INFO - step 170: train_loss: 1.0175, epoch: 1, lr: 4.04e-05\n",
      "2025-03-10 17:23:52,012 - qurious.llms.trainer - INFO - step 180: train_loss: 1.1776, epoch: 1, lr: 3.99e-05\n",
      "2025-03-10 17:23:54,540 - qurious.llms.trainer - INFO - step 190: train_loss: 1.0225, epoch: 1, lr: 3.93e-05\n",
      "2025-03-10 17:23:57,079 - qurious.llms.trainer - INFO - step 200: train_loss: 1.0546, epoch: 1, lr: 3.88e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501012d58985471393fff5cf5827a75c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 17:23:59,609 - qurious.llms.trainer - INFO - step 200: eval_loss: 0.7909\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6f98f8b86a4489bef8e4f761429c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 17:24:02,303 - qurious.llms.trainer - INFO - step 210: train_loss: 0.9580, epoch: 2, lr: 3.82e-05\n",
      "2025-03-10 17:24:04,931 - qurious.llms.trainer - INFO - step 220: train_loss: 1.0205, epoch: 2, lr: 3.76e-05\n",
      "2025-03-10 17:24:07,432 - qurious.llms.trainer - INFO - step 230: train_loss: 1.0382, epoch: 2, lr: 3.71e-05\n",
      "2025-03-10 17:24:09,975 - qurious.llms.trainer - INFO - step 240: train_loss: 0.9844, epoch: 2, lr: 3.65e-05\n",
      "2025-03-10 17:24:12,549 - qurious.llms.trainer - INFO - step 250: train_loss: 1.0037, epoch: 2, lr: 3.59e-05\n",
      "2025-03-10 17:24:15,116 - qurious.llms.trainer - INFO - step 260: train_loss: 1.1032, epoch: 2, lr: 3.54e-05\n",
      "2025-03-10 17:24:17,659 - qurious.llms.trainer - INFO - step 270: train_loss: 0.9423, epoch: 2, lr: 3.48e-05\n",
      "2025-03-10 17:24:20,158 - qurious.llms.trainer - INFO - step 280: train_loss: 1.2137, epoch: 2, lr: 3.43e-05\n",
      "2025-03-10 17:24:22,655 - qurious.llms.trainer - INFO - step 290: train_loss: 1.0775, epoch: 2, lr: 3.37e-05\n",
      "2025-03-10 17:24:25,136 - qurious.llms.trainer - INFO - step 300: train_loss: 1.0963, epoch: 2, lr: 3.31e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ffa783445c480baac7ebc87c3771c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 17:24:27,641 - qurious.llms.trainer - INFO - step 300: eval_loss: 0.9329\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b08d8b0fab74f66a2c0d0e496c9f938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 17:24:30,200 - qurious.llms.trainer - INFO - step 310: train_loss: 0.8827, epoch: 3, lr: 3.26e-05\n",
      "2025-03-10 17:24:32,706 - qurious.llms.trainer - INFO - step 320: train_loss: 1.1469, epoch: 3, lr: 3.20e-05\n",
      "2025-03-10 17:24:35,200 - qurious.llms.trainer - INFO - step 330: train_loss: 0.9879, epoch: 3, lr: 3.14e-05\n",
      "2025-03-10 17:24:37,718 - qurious.llms.trainer - INFO - step 340: train_loss: 1.0194, epoch: 3, lr: 3.09e-05\n",
      "2025-03-10 17:24:40,211 - qurious.llms.trainer - INFO - step 350: train_loss: 1.1099, epoch: 3, lr: 3.03e-05\n",
      "2025-03-10 17:24:42,755 - qurious.llms.trainer - INFO - step 360: train_loss: 0.9169, epoch: 3, lr: 2.98e-05\n",
      "2025-03-10 17:24:45,274 - qurious.llms.trainer - INFO - step 370: train_loss: 1.0286, epoch: 3, lr: 2.92e-05\n",
      "2025-03-10 17:24:47,780 - qurious.llms.trainer - INFO - step 380: train_loss: 0.9116, epoch: 3, lr: 2.86e-05\n",
      "2025-03-10 17:24:50,296 - qurious.llms.trainer - INFO - step 390: train_loss: 1.1038, epoch: 3, lr: 2.81e-05\n",
      "2025-03-10 17:24:52,893 - qurious.llms.trainer - INFO - step 400: train_loss: 1.1309, epoch: 3, lr: 2.75e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0ab07b20a8b455686ac8ec730cd52cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 17:24:55,408 - qurious.llms.trainer - INFO - step 400: eval_loss: 0.8381\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba93e13fecfb4d5ea49eca77347ffd1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 17:24:57,952 - qurious.llms.trainer - INFO - step 410: train_loss: 1.0542, epoch: 4, lr: 2.69e-05\n",
      "2025-03-10 17:25:00,519 - qurious.llms.trainer - INFO - step 420: train_loss: 1.0297, epoch: 4, lr: 2.64e-05\n",
      "2025-03-10 17:25:03,093 - qurious.llms.trainer - INFO - step 430: train_loss: 0.9424, epoch: 4, lr: 2.58e-05\n",
      "2025-03-10 17:25:05,694 - qurious.llms.trainer - INFO - step 440: train_loss: 1.0396, epoch: 4, lr: 2.53e-05\n",
      "2025-03-10 17:25:08,390 - qurious.llms.trainer - INFO - step 450: train_loss: 1.2363, epoch: 4, lr: 2.47e-05\n",
      "2025-03-10 17:25:11,098 - qurious.llms.trainer - INFO - step 460: train_loss: 0.9789, epoch: 4, lr: 2.41e-05\n",
      "2025-03-10 17:25:13,678 - qurious.llms.trainer - INFO - step 470: train_loss: 1.0828, epoch: 4, lr: 2.36e-05\n",
      "2025-03-10 17:25:16,331 - qurious.llms.trainer - INFO - step 480: train_loss: 1.2786, epoch: 4, lr: 2.30e-05\n",
      "2025-03-10 17:25:19,006 - qurious.llms.trainer - INFO - step 490: train_loss: 1.1891, epoch: 4, lr: 2.24e-05\n",
      "2025-03-10 17:25:21,793 - qurious.llms.trainer - INFO - step 500: train_loss: 1.1204, epoch: 4, lr: 2.19e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9537c0fd38d149c5b249a2cb7df08a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 17:25:24,505 - qurious.llms.trainer - INFO - step 500: eval_loss: 0.9036\n",
      "2025-03-10 17:25:24,509 - qurious.llms.trainer - INFO - Training completed. Best eval_loss was at epoch 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run loud-eel-800 at: http://127.0.0.1:5000/#/experiments/926729112683475320/runs/87405fdab2e041cfbe8ff836b7ebcc08\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/926729112683475320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': [2.622568038702011,\n",
       "  1.0216279006004334,\n",
       "  1.0142583006620407,\n",
       "  1.04672212600708,\n",
       "  1.0777782374620437],\n",
       " 'eval_loss': [0.8202412390708923,\n",
       "  0.7909462666511535,\n",
       "  0.9328550434112549,\n",
       "  0.8380931901931763,\n",
       "  0.9036318516731262]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from qurious.llms.trainer import Trainer\n",
    "\n",
    "# make data loaders for PyTorch format\n",
    "train_dataloader = DataLoader(tokenized_train_dataset.with_format(\"torch\"), batch_size=8, shuffle=True)\n",
    "eval_dataloader = DataLoader(tokenized_eval_dataset.with_format(\"torch\"), batch_size=8, shuffle=False)\n",
    "\n",
    "optimizer = AdamW(peft_model.parameters(), lr=config.training.learning_rate, weight_decay=0.01)\n",
    "scheduler = LinearLR(optimizer, start_factor=1, end_factor=0.1, total_iters=len(dataset[\"train\"]))\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    config=config,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    loggers=[\"console\", \"mlflow\"],\n",
    "    experiment_name=\"maze-gpt2-finetune\",\n",
    "    loss_fn=loss_fn,\n",
    ")\n",
    "\n",
    "trainer.train(train_dataloader=train_dataloader, eval_dataloader=eval_dataloader, num_epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
