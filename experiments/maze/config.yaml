model:
  base_model: meta-llama/Llama-3.1-8B-Instruct
  device: auto
  lora_enabled: true
  lora_config:
    bias: none
    lora_alpha: 16
    lora_dropout: 0.05
    r: 8
    target_modules: all-linear
    task_type: CAUSAL_LM
paths:
  checkpoint_dir: ./checkpoints
  data_path: ../../data/grid_world_1k.jsonl
training:
  batch_size: 4
  epochs: 5
  eval_interval: 500
  learning_rate: 5e-5
  log_interval: 10
  max_eval_samples: 50
  max_grad_norm: 1.0
  save_interval: 1000
  scheduler_step_per_batch: true
